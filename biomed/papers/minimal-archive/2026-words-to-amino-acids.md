---
paper_id: "arxiv:2502.00001"
title: "From Words to Amino Acids: Does the Curse of Depth Persist?"
authors:
  - "Aleena Siji"
  - "Amir Mohammad Karimi Mamaghan"
  - "Michael Heinzinger"
  - "Stefan Bauer"
year: 2026
venue: "arXiv"
urls:
  paper_url: "https://arxiv.org/abs/2502.00001"
direction: "biomed"
topic: "protein-language-models"
tags: ["plm", "curse-of-depth", "transformer"]
journal_tier: 4
quality_score: 3
status: "minimal"
decision: "P1"
is_zheng_shuangjia_paper: false
added_date: "2026-02-28"
---

# From Words to Amino Acids: Does the Curse of Depth Persist?

## 一句话总结
探究蛋白质语言模型(PLM)是否像自然语言模型一样存在深度诅咒问题。

## 核心内容
- **问题**: PLM 随着层数增加是否出现性能下降（curse of depth）
- **方法**: 对比分析 PLM 和 NLP transformer 的深度行为
- **意义**: 为 PLM 架构设计提供理论指导

## 关联性
- 与 ZSJ 研究方向相关：蛋白质表示学习
- 可纳入 BioMed 知识库 P1 优先级

## 待深入
- [ ] 获取完整 PDF 分析实验结果
- [ ] 对比不同深度 PLM 的性能曲线
